# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EBYMrN9m3bJHUmxSb792BnH4HlDprTfX

## Google Colab Utils
"""

# from google.colab import drive
# drive.mount("/content/drive/")

# import os
# path = "/content/drive/My Drive/SEM 07 AKSHILMY/Machine Learning-S7-CS4622/ML Lab 01"
# os.chdir(path)

# Commented out IPython magic to ensure Python compatibility.
# %pip install numpy pandas matplotlib seaborn scikit-learn

"""## Import Libraries"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""## Initialization of global variables"""

LABEL_1 = "label_1"
LABEL_2 = "label_2"
LABEL_3 = "label_3"
LABEL_4 = "label_4"

LABELS = [LABEL_1,LABEL_2,LABEL_3,LABEL_4]
FEATURES = [f"feature_{i+1}" for i in range(0,256)]

"""## Analysis of Dataset"""

# Commented out IPython magic to ensure Python compatibility.
# %ls dataset

TRAIN_DF = pd.read_csv("dataset/train.csv")
VALID_DF = pd.read_csv("dataset/valid.csv")
TEST_DF = pd.read_csv("dataset/test.csv")

TRAIN_DF.head()

VALID_DF.head()

"""#### Collecting Statistical Information on train dataset"""

TRAIN_DF.info()

TRAIN_DF[FEATURES].describe()

TRAIN_DF[LABELS].describe()

"""### Bias observed in `label_4`"""

TRAIN_DF[LABEL_4].value_counts()

"""## Preprocessing"""

from sklearn.preprocessing import RobustScaler
from sklearn import svm
from sklearn import metrics

x_train_dict = {}
y_train_dict = {}
x_valid_dict = {}
y_valid_dict = {}

"""#### Scaling"""

for target_label in LABELS:
  train_df_copy = TRAIN_DF[TRAIN_DF[LABEL_2].notna()] if target_label == LABEL_2 else TRAIN_DF
  valid_df_copy = VALID_DF[VALID_DF[LABEL_2].notna()] if target_label == LABEL_2 else VALID_DF

  scaler = RobustScaler()

  x_train_dict[target_label] = pd.DataFrame(scaler.fit_transform(train_df_copy.drop(LABELS,axis=1)),columns=FEATURES)
  y_train_dict[target_label] = train_df_copy[target_label]

  x_valid_dict[target_label] = pd.DataFrame(scaler.transform(valid_df_copy.drop(LABELS,axis=1)),columns=FEATURES)
  y_valid_dict[target_label] = valid_df_copy[target_label]

"""## Analysis on Classification before feature engineering

### Correlation Matrix
"""

train_df = TRAIN_DF.drop(LABELS,axis=True)
corr_matrix = train_df.corr()
corr_threshold = 0.5

corr_matrix = corr_matrix[(corr_matrix>corr_threshold) | (corr_matrix<-corr_threshold)]
plt.figure(figsize=(18,8))
sns.heatmap(corr_matrix,annot= True,cmap="coolwarm",center=0)

"""### Accuracy using Support Vector Classification"""

def get_accuracy(x_train,y_train,x_valid,y_valid,classifier="svc",params={"kernel" : "linear","average": "weighted","class_weight": None}):
  if classifier=="svc":
    classifier = svm.SVC(kernel=params['kernel'],class_weight = params["class_weight"])
    classifier.fit(x_train,y_train)
  y_pred = classifier.predict(x_valid)
  conf_matrix = metrics.confusion_matrix(y_valid,y_pred)
  accuracy = metrics.accuracy_score(y_valid,y_pred)
  precision = metrics.precision_score(y_valid,y_pred,average=params["average"])
  recall = metrics.recall_score(y_valid,y_pred,average=params["average"])
  return conf_matrix,accuracy,precision,recall

"""#### Label 1"""

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_dict[LABEL_1],
    y_train = y_train_dict[LABEL_1],
    x_valid = x_valid_dict[LABEL_1],
    y_valid = y_valid_dict[LABEL_1],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 2"""

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_dict[LABEL_2],
    y_train = y_train_dict[LABEL_2],
    x_valid = x_valid_dict[LABEL_2],
    y_valid = y_valid_dict[LABEL_2],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 3"""

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_dict[LABEL_3],
    y_train = y_train_dict[LABEL_3],
    x_valid = x_valid_dict[LABEL_3],
    y_valid = y_valid_dict[LABEL_3],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 4"""

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_dict[LABEL_4],
    y_train = y_train_dict[LABEL_4],
    x_valid = x_valid_dict[LABEL_4],
    y_valid = y_valid_dict[LABEL_4],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""## Feature Engineering Techniques"""

from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.decomposition import PCA

"""### Univariate feature selection

#### SelectKBest with ANOVA F-value
"""

def select_k_best_using_ANOVA_F(x_train,y_train,x_valid,k=100):
  selector = SelectKBest(f_classif,k = k)
  x_train_now = selector.fit_transform(x_train,y_train)
  x_valid_now = selector.transform(x_valid)
  return x_train_now,x_valid_now,selector

"""##### Label 1"""

num_of_features_expected = 100

x_train_now,x_valid_now,selector = select_k_best_using_ANOVA_F(
    x_train = x_train_dict[LABEL_1],
    y_train = y_train_dict[LABEL_1],
    x_valid = x_valid_dict[LABEL_1],
    k = num_of_features_expected,
)

conf_matrix,accuracy,precision,recall = get_accuracy(
      x_train= x_train_now,
      y_train = y_train_dict[LABEL_1],
      x_valid = x_valid_now,
      y_valid = y_valid_dict[LABEL_1],
      classifier="svc",
      params = {
          "kernel" : "linear",
          "average" : "weighted",
          "class_weight": None
      }
  )

conf_matrix

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

assert x_valid_now.shape[1] == num_of_features_expected
print(f"Number of Features now : {x_valid_now.shape[1]}")

selector.get_feature_names_out()

"""##### Label 2"""

num_of_features_expected = 230

x_train_now,x_valid_now,selector = select_k_best_using_ANOVA_F(
    x_train = x_train_dict[LABEL_2],
    y_train = y_train_dict[LABEL_2],
    x_valid = x_valid_dict[LABEL_2],
    k = num_of_features_expected,
)

conf_matrix,accuracy,precision,recall = get_accuracy(
      x_train= x_train_now,
      y_train = y_train_dict[LABEL_2],
      x_valid = x_valid_now,
      y_valid = y_valid_dict[LABEL_2],
      classifier="svc",
      params = {
          "kernel" : "linear",
          "average" : "weighted",
          "class_weight": None
      }
  )

conf_matrix

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

assert x_valid_now.shape[1] == num_of_features_expected
print(f"Number of Features now : {x_valid_now.shape[1]}")

selector.get_feature_names_out()

"""##### Label 3"""

num_of_features_expected = 80

x_train_now,x_valid_now,selector = select_k_best_using_ANOVA_F(
    x_train = x_train_dict[LABEL_3],
    y_train = y_train_dict[LABEL_3],
    x_valid = x_valid_dict[LABEL_3],
    k = num_of_features_expected,
)

conf_matrix,accuracy,precision,recall = get_accuracy(
      x_train= x_train_now,
      y_train = y_train_dict[LABEL_3],
      x_valid = x_valid_now,
      y_valid = y_valid_dict[LABEL_3],
      classifier="svc",
      params = {
          "kernel" : "linear",
          "average" : "weighted",
          "class_weight": None
      }
  )

conf_matrix

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

assert x_valid_now.shape[1] == num_of_features_expected
print(f"Number of Features now : {x_valid_now.shape[1]}")

selector.get_feature_names_out()

"""##### Label 4"""

num_of_features_expected = 230

x_train_now,x_valid_now,selector = select_k_best_using_ANOVA_F(
    x_train = x_train_dict[LABEL_4],
    y_train = y_train_dict[LABEL_4],
    x_valid = x_valid_dict[LABEL_4],
    k = num_of_features_expected,
)

conf_matrix,accuracy,precision,recall = get_accuracy(
      x_train= x_train_now,
      y_train = y_train_dict[LABEL_4],
      x_valid = x_valid_now,
      y_valid = y_valid_dict[LABEL_4],
      classifier="svc",
      params = {
          "kernel" : "linear",
          "average" : "weighted",
          "class_weight": "balanced"
      }
  )

conf_matrix

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

assert x_valid_now.shape[1] == num_of_features_expected
print(f"Number of Features now : {x_valid_now.shape[1]}")

selector.get_feature_names_out()

"""### Principal Component Analysis"""

def PCA_transform(x_train,x_valid,n_components=0.95,svd_solver="full"):
  pca = PCA(n_components=n_components,svd_solver=svd_solver)
  pca.fit(x_train)
  x_train_trf = pd.DataFrame(pca.transform(x_train))
  x_valid_trf = pd.DataFrame(pca.transform(x_valid))
  return x_train_trf,x_valid_trf,pca

"""#### Label 1"""

# Collection of all 256 features is still required
x_train_trf,x_valid_trf,pca = PCA_transform(
    x_train = x_train_dict[LABEL_1],
    x_valid = x_valid_dict[LABEL_1],
    n_components = 0.95,
    svd_solver = "full",

)

print(f"Shape after PCA: {x_train_trf.shape}")

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_trf,
    y_train = y_train_dict[LABEL_1],
    x_valid = x_valid_trf,
    y_valid = y_valid_dict[LABEL_1],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 2"""

# Collection of all 256 features is still required
x_train_trf,x_valid_trf,pca = PCA_transform(
    x_train = x_train_dict[LABEL_2],
    x_valid = x_valid_dict[LABEL_2],
    n_components = 0.95,
    svd_solver = "full",

)

print(f"Shape after PCA: {x_train_trf.shape}")

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_trf,
    y_train = y_train_dict[LABEL_2],
    x_valid = x_valid_trf,
    y_valid = y_valid_dict[LABEL_2],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 3"""

# Collection of all 256 features is still required
x_train_trf,x_valid_trf,pca = PCA_transform(
    x_train = x_train_dict[LABEL_3],
    x_valid = x_valid_dict[LABEL_3],
    n_components = 0.95,
    svd_solver = "full",

)

print(f"Shape after PCA: {x_train_trf.shape}")

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_trf,
    y_train = y_train_dict[LABEL_3],
    x_valid = x_valid_trf,
    y_valid = y_valid_dict[LABEL_3],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 4"""

# Collection of all 256 features is still required
x_train_trf,x_valid_trf,pca = PCA_transform(
    x_train = x_train_dict[LABEL_4],
    x_valid = x_valid_dict[LABEL_4],
    n_components = 0.95,
    svd_solver = "full",

)

print(f"Shape after PCA: {x_train_trf.shape}")

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_trf,
    y_train = y_train_dict[LABEL_4],
    x_valid = x_valid_trf,
    y_valid = y_valid_dict[LABEL_4],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": "balanced"
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""### Combination of the above two techniques

#### Label 1
"""

num_of_features_expected = 230

# Collection of all 256 features is not yet required
x_train_now,x_valid_now,selector = select_k_best_using_ANOVA_F(
    x_train = x_train_dict[LABEL_1],
    y_train = y_train_dict[LABEL_1],
    x_valid = x_valid_dict[LABEL_1],
    k = num_of_features_expected,
)
x_train_trf,x_valid_trf,pca = PCA_transform(
    x_train = x_train_now,
    x_valid = x_valid_now,
    n_components = 0.99,
    svd_solver = "full",

)

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_trf,
    y_train = y_train_dict[LABEL_1],
    x_valid = x_valid_trf,
    y_valid = y_valid_dict[LABEL_1],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 2"""

num_of_features_expected = 240

# Collection of all 256 features is not yet required
x_train_now,x_valid_now,selector = select_k_best_using_ANOVA_F(
    x_train = x_train_dict[LABEL_2],
    y_train = y_train_dict[LABEL_2],
    x_valid = x_valid_dict[LABEL_2],
    k = num_of_features_expected,
)
x_train_trf,x_valid_trf,pca = PCA_transform(
    x_train = x_train_now,
    x_valid = x_valid_now,
    n_components = 0.99,
    svd_solver = "full",

)

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_trf,
    y_train = y_train_dict[LABEL_2],
    x_valid = x_valid_trf,
    y_valid = y_valid_dict[LABEL_2],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 3"""

num_of_features_expected = 100

# Collection of all 256 features is not yet required
x_train_now,x_valid_now,selector = select_k_best_using_ANOVA_F(
    x_train = x_train_dict[LABEL_3],
    y_train = y_train_dict[LABEL_3],
    x_valid = x_valid_dict[LABEL_3],
    k = num_of_features_expected,
)
x_train_trf,x_valid_trf,pca = PCA_transform(
    x_train = x_train_now,
    x_valid = x_valid_now,
    n_components = 0.99,
    svd_solver = "full",

)

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_trf,
    y_train = y_train_dict[LABEL_3],
    x_valid = x_valid_trf,
    y_valid = y_valid_dict[LABEL_3],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""#### Label 4"""

num_of_features_expected = 250

# Collection of all 256 features is not yet required
x_train_now,x_valid_now,selector = select_k_best_using_ANOVA_F(
    x_train = x_train_dict[LABEL_4],
    y_train = y_train_dict[LABEL_4],
    x_valid = x_valid_dict[LABEL_4],
    k = num_of_features_expected,
)
x_train_trf,x_valid_trf,pca = PCA_transform(
    x_train = x_train_now,
    x_valid = x_valid_now,
    n_components = 0.99,
    svd_solver = "full",

)

conf_matrix,accuracy,precision,recall = get_accuracy(
    x_train= x_train_trf,
    y_train = y_train_dict[LABEL_4],
    x_valid = x_valid_trf,
    y_valid = y_valid_dict[LABEL_4],
    classifier="svc",
    params = {
        "kernel" : "linear",
        "average" : "weighted",
        "class_weight": None
    }
)

print(conf_matrix)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")

"""## Test Dataset"""

TEST_DF = pd.read_csv("dataset/test.csv")
features_df = TEST_DF.drop(LABELS,axis=1)

scaler = RobustScaler()

scaled_features_df = pd.DataFrame(scaler.fit_transform(features_df),columns=FEATURES)

"""### Label 1"""

k = 230
n_components = 0.99

label1_file_name = "label1.csv"

label_csv_columns = [
    "Predicted labels before feature engineering",
    "Predicted labels after feature engineering",
    "No of new features"
]

label1_df = pd.DataFrame(columns=label_csv_columns)

classifier = svm.SVC(kernel="linear",class_weight = None)
classifier.fit(x_train_dict[LABEL_1],y_train_dict[LABEL_1])
labels_before = classifier.predict(scaled_features_df)

label1_df[label_csv_columns[0]] = labels_before

label1_df

selector = SelectKBest(f_classif,k=k)
x_train_now = selector.fit_transform(x_train_dict[LABEL_1],y_train_dict[LABEL_1])
pca = PCA(n_components=n_components,svd_solver="full")
pca.fit(x_train_now)
x_train_trf = pd.DataFrame(pca.transform(x_train_now))

scaled_features_df_now = selector.transform(scaled_features_df)
scaled_features_df_now = pca.transform(scaled_features_df_now)

classifier = svm.SVC(kernel="linear",class_weight = None)
classifier.fit(x_train_trf,y_train_dict[LABEL_1])
labels_after = classifier.predict(scaled_features_df_now)

label1_df[label_csv_columns[1]] = labels_after

label1_df

column_names = [f'new_feature_{i}' for i in range(1, scaled_features_df_now.shape[1]+1)]  # Generating column names
df = pd.DataFrame(scaled_features_df_now, columns=column_names)
label1_df = pd.concat([label1_df, df], axis=1)

label1_df.to_csv(label1_file_name, index=False)

label1_df

"""### Label 2"""

k = 240
n_components = 0.99

label2_file_name = "label2.csv"

label_csv_columns = [
    "Predicted labels before feature engineering",
    "Predicted labels after feature engineering",
    "No of new features"
]

label2_df = pd.DataFrame(columns=label_csv_columns)

classifier = svm.SVC(kernel="linear",class_weight = None)
classifier.fit(x_train_dict[LABEL_2],y_train_dict[LABEL_2])
labels_before = classifier.predict(scaled_features_df)

label2_df[label_csv_columns[0]] = labels_before

label2_df

selector = SelectKBest(f_classif,k = k)
x_train_now = selector.fit_transform(x_train_dict[LABEL_2],y_train_dict[LABEL_2])
pca = PCA(n_components=n_components,svd_solver="full")
pca.fit(x_train_now)
x_train_trf = pd.DataFrame(pca.transform(x_train_now))

scaled_features_df_now = selector.transform(scaled_features_df)
scaled_features_df_now = pca.transform(scaled_features_df_now)

classifier = svm.SVC(kernel="linear",class_weight = None)
classifier.fit(x_train_trf,y_train_dict[LABEL_2])
labels_after = classifier.predict(scaled_features_df_now)

label2_df[label_csv_columns[1]] = labels_after

label2_df

column_names = [f'new_feature_{i}' for i in range(1, scaled_features_df_now.shape[1]+1)]
df = pd.DataFrame(scaled_features_df_now, columns=column_names)
label2_df = pd.concat([label2_df, df], axis=1)

label2_df.to_csv(label2_file_name, index=False)

"""### Label 3"""

k = 100
n_components = 0.99

label3_file_name = "label3.csv"

label_csv_columns = [
    "Predicted labels before feature engineering",
    "Predicted labels after feature engineering",
    "No of new features"
]

label3_df = pd.DataFrame(columns=label_csv_columns)

classifier = svm.SVC(kernel="linear",class_weight = None)
classifier.fit(x_train_dict[LABEL_3],y_train_dict[LABEL_3])
labels_before = classifier.predict(scaled_features_df)

label3_df[label_csv_columns[0]] = labels_before

label3_df

selector = SelectKBest(f_classif,k = k)
x_train_now = selector.fit_transform(x_train_dict[LABEL_3],y_train_dict[LABEL_3])
pca = PCA(n_components=n_components,svd_solver="full")
pca.fit(x_train_now)
x_train_trf = pd.DataFrame(pca.transform(x_train_now))

scaled_features_df_now = selector.transform(scaled_features_df)
scaled_features_df_now = pca.transform(scaled_features_df_now)

classifier = svm.SVC(kernel="linear",class_weight = None)
classifier.fit(x_train_trf,y_train_dict[LABEL_3])
labels_after = classifier.predict(scaled_features_df_now)

label3_df[label_csv_columns[1]] = labels_after

label3_df

column_names = [f'new_feature_{i}' for i in range(1, scaled_features_df_now.shape[1])]
df = pd.DataFrame(scaled_features_df_now, columns=column_names)
label3_df = pd.concat([label3_df, df], axis=1)

label3_df.to_csv(label3_file_name, index=False)

"""### Label 4"""

k = 250
n_components = 0.99

label4_file_name = "label4.csv"

label_csv_columns = [
    "Predicted labels before feature engineering",
    "Predicted labels after feature engineering",
    "No of new features"
]

label4_df = pd.DataFrame(columns=label_csv_columns)

classifier = svm.SVC(kernel="linear",class_weight = "balanced")
classifier.fit(x_train_dict[LABEL_4],y_train_dict[LABEL_4])
labels_before = classifier.predict(scaled_features_df)

label4_df[label_csv_columns[0]] = labels_before

label4_df

selector = SelectKBest(f_classif,k = k)
x_train_now = selector.fit_transform(x_train_dict[LABEL_4],y_train_dict[LABEL_4])
pca = PCA(n_components=n_components,svd_solver="full")
pca.fit(x_train_now)
x_train_trf = pd.DataFrame(pca.transform(x_train_now))

scaled_features_df_now = selector.transform(scaled_features_df)
scaled_features_df_now = pca.transform(scaled_features_df_now)

classifier = svm.SVC(kernel="linear",class_weight = None)
classifier.fit(x_train_trf,y_train_dict[LABEL_4])
labels_after = classifier.predict(scaled_features_df_now)

label4_df[label_csv_columns[1]] = labels_after

label4_df

column_names = [f'new_feature_{i}' for i in range(1, scaled_features_df_now.shape[1])]
df = pd.DataFrame(scaled_features_df_now, columns=column_names)
label4_df = pd.concat([label4_df, df], axis=1)

label4_df.to_csv(label4_file_name, index=False)